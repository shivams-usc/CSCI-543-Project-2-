#!/usr/bin/env python3
"""
Neural Network Training - 
"""

import csv
import random
import math
import pickle

class SimpleNN:
    """2-layer neural network: 4 inputs → 8 hidden → 1 output"""
    
    def __init__(self):
        # Initialize weights randomly
        random.seed(42)
        self.W1 = [[random.uniform(-0.1, 0.1) for _ in range(8)] for _ in range(4)]
        self.b1 = [0.0] * 8
        self.W2 = [[random.uniform(-0.1, 0.1)] for _ in range(8)]
        self.b2 = [0.0]
    
    def sigmoid(self, x):
        """Sigmoid activation function"""
        try:
            return 1.0 / (1.0 + math.exp(-max(-500, min(500, x))))
        except:
            return 0.0 if x < 0 else 1.0
    
    def forward(self, X):
        """Forward pass through network"""
        # Hidden layer
        hidden = []
        for i in range(8):
            sum_val = self.b1[i]
            for j in range(4):
                sum_val += X[j] * self.W1[j][i]
            hidden.append(self.sigmoid(sum_val))
        
        # Output layer
        output = self.b2[0]
        for i in range(8):
            output += hidden[i] * self.W2[i][0]
        output = self.sigmoid(output)
        
        return output
    
    def train(self, X_data, y_data, epochs=200, learning_rate=0.01):
        """Train the network using backpropagation"""
        print(f"Training neural network for {epochs} epochs...")
        
        for epoch in range(epochs):
            total_loss = 0.0
            for idx in range(len(X_data)):
                X = X_data[idx]
                y = y_data[idx]
                
                # Forward pass
                hidden = []
                for i in range(8):
                    sum_val = self.b1[i]
                    for j in range(4):
                        sum_val += X[j] * self.W1[j][i]
                    hidden.append(self.sigmoid(sum_val))
                
                output = self.b2[0]
                for i in range(8):
                    output += hidden[i] * self.W2[i][0]
                output = self.sigmoid(output)
                
                # Calculate loss
                error = output - y
                total_loss += error * error
                
                # Backward pass (simplified gradient descent)
                # Output layer gradients
                d_output = error * output * (1 - output)
                
                # Hidden layer gradients
                d_hidden = [0.0] * 8
                for i in range(8):
                    d_hidden[i] = d_output * self.W2[i][0] * hidden[i] * (1 - hidden[i])
                
                # Update weights
                for i in range(8):
                    self.W2[i][0] -= learning_rate * d_output * hidden[i]
                    self.b2[0] -= learning_rate * d_output
                    
                    for j in range(4):
                        self.W1[j][i] -= learning_rate * d_hidden[i] * X[j]
                    self.b1[i] -= learning_rate * d_hidden[i]
            
            if epoch % 50 == 0:
                avg_loss = total_loss / len(X_data)
                print(f"Epoch {epoch:3d}, Loss: {avg_loss:.6f}")
        
        avg_loss = total_loss / len(X_data)
        print(f"Training complete! Final loss: {avg_loss:.6f}")
        return avg_loss

def load_training_data(filename='page_log.csv'):
    """Load training data from CSV"""
    import os
    if not os.path.exists(filename):
        print(f"ERROR: {filename} not found!")
        print("Run generate_synthetic_data.py first to create training data.")
        return None, None
    
    print(f"Loading training data from {filename}...")
    X_data = []
    y_data = []
    
    with open(filename, 'r') as f:
        reader = csv.reader(f)
        next(reader)  # Skip header
        
        for row in reader:
            if len(row) < 4:
                continue
            
            try:
                access_count = float(row[0]) / 100.0  # Normalize
                time_since = float(row[1]) / 1000.0   # Normalize
                is_dirty = float(row[2])
                has_refs = float(row[3])
                
                X_data.append([access_count, time_since, is_dirty, has_refs])
                
                # Generate label: keep pages with high access or recent access
                label = 1.0 if (access_count > 0.5 or time_since < 0.5) else 0.0
                y_data.append(label)
            except:
                continue
    
    print(f"Loaded {len(X_data)} samples")
    return X_data, y_data

def save_weights_c_header(nn, filename='nn_weights.h'):
    """Save weights as C header file"""
    with open(filename, 'w') as f:
        f.write("// Auto-generated neural network weights\n")
        f.write("// Generated by train_simple_nn.py\n\n")
        f.write("#ifndef NN_WEIGHTS_H\n#define NN_WEIGHTS_H\n\n")
        
        # W1
        f.write("static float W1[4][8] = {\n")
        for i in range(4):
            f.write("    {")
            f.write(", ".join([f"{nn.W1[i][j]:.6f}f" for j in range(8)]))
            f.write("}")
            if i < 3:
                f.write(",")
            f.write("\n")
        f.write("};\n\n")
        
        # b1
        f.write("static float b1[8] = {")
        f.write(", ".join([f"{nn.b1[i]:.6f}f" for i in range(8)]))
        f.write("};\n\n")
        
        # W2
        f.write("static float W2[8][1] = {\n")
        for i in range(8):
            f.write(f"    {{{nn.W2[i][0]:.6f}f}}")
            if i < 7:
                f.write(",")
            f.write("\n")
        f.write("};\n\n")
        
        # b2
        f.write(f"static float b2[1] = {{{nn.b2[0]:.6f}f}};\n\n")
        f.write("#endif\n")
    
    print(f"C header saved to {filename}")

def main():
    print("=" * 60)
    print("Simple Neural Network Training for SQLite Cache")
    print("=" * 60)
    print()
    
    # Load data
    X_data, y_data = load_training_data()
    if X_data is None:
        return
    
    if len(X_data) < 100:
        print("WARNING: Very few samples. Results may be poor.")
    
    # Create and train network
    nn = SimpleNN()
    final_loss = nn.train(X_data, y_data, epochs=200)
    
    # Test prediction on a few samples
    print(f"\nSample predictions (first 5):")
    for i in range(min(5, len(X_data))):
        pred = nn.forward(X_data[i])
        print(f"  Sample {i}: features={X_data[i]}, label={y_data[i]:.1f}, prediction={pred:.3f}")
    
    # Save weights
    save_weights_c_header(nn)
    
    print("\n" + "=" * 60)
    print("Training Complete!")
    print("=" * 60)
    print("\nNext steps:")
    print("1. Include nn_weights.h in your C code")
    print("2. Use the weights in ml_scoring.c")
    print("3. Rebuild SQLite and test!")

if __name__ == "__main__":
    main()

